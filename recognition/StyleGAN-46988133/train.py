"""
train.py created by Matthew Lockett 46988133
"""
import os
import math
import random
import time
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.optim as optim
import torch.utils.data
import torchvision.utils as vutils
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import hyperparameters as hp
from dataset import load_ADNI_dataset
from modules import *
from utils import *

# Used to remove the Qt backend of matplotlib causing issues
matplotlib.use("Agg")

# Force the creation of a folder to save figures if not present 
os.makedirs(hp.SAVED_OUTPUT_DIR, exist_ok=True)

# PyTorch Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
if not torch.cuda.is_available():
    print("Warning CUDA not Found. Using CPU.")

# Set random seed for reproducibility
print("Random Seed Used: ", hp.RANDOM_SEED)
random.seed(hp.RANDOM_SEED)
torch.manual_seed(hp.RANDOM_SEED)
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
torch.use_deterministic_algorithms(True) # Needed for reproducible results

# Setup both the generator and discriminator models
gen = Generator().to(device)
disc = Discriminator().to(device)

# Create the optimisers used by the genertator and discriminator during training 
gen_opt = optim.Adam(gen.parameters(), lr=hp.GEN_LEARNING_RATE, betas=(0.5, 0.999))
disc_opt = optim.Adam(disc.parameters(), lr=hp.DISC_LEARNING_RATE, betas=(0.5, 0.999))

# Initialise Loss Functions
adversial_criterion = nn.BCELoss()
class_criterion = nn.CrossEntropyLoss()

# Initialise the real and fake labels for training
real_label = 1.0
fake_label = 0.0

# Create a collection of latent vectors used later to visualise the progression of the generator 
fixed_noise = torch.randn(64, hp.LATENT_SIZE, device=device)

# Lists to keep track of progress and statistics 
img_list = []
G_losses = []
D_losses = []
iters = 0

###################################### Training Loop ###################################

# Start time of the training loop
training_start_time = time.time()

# REF: This training loop was inspired by the following PyTorch tutorial: 
# REF: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html?highlight=dcgan.
# REF: The OASIS GAN demo 2 for Matthew Lockett 46988133, was also used heavily as inspiration.
# REF: The mixing regularisation portion was inspired by code generated by ChatGPT-4o.
# REF: Based on the following prompt: How can I implement mixing regularization into my StyleGAN model?
# REF: The following code was also inspired by chatGPT-o1-preview via the following prompts:
# REF: Prompt: How should I write my discriminator to output both a rating for fake/real and a rating 
# REF: for class AD or CN while embedding the class information into the discriminator as well?
# REF: Prompt: How do I create a training loop that can be used for a Progressive GAN architecture
print("Starting Training Loop...")
for current_depth in range(hp.START_DEPTH, hp.MAX_DEPTH + 1):

    # Set the current resolution (starts at 8x8)
    current_resolution = 8 * (2 ** current_depth)
    print(f"\nTraining at resolution: {current_resolution}x{current_resolution}")

    # Load the ADNI dataset in at the current resolution
    train_loader = load_ADNI_dataset(image_size=current_resolution, training_set=True)

    real_batch = next(iter(train_loader))
    plt.figure(figsize=(8,8))
    plt.axis("off")
    plt.title("Sample Training Images for the ADNI Dataset")
    plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))
    plt.savefig(os.path.join(hp.SAVED_OUTPUT_DIR, "adni_sample_images.png"), pad_inches=0)
    plt.close()

    # Reset the alpha and step counters
    alpha = 0.0
    total_steps = 0
    total_steps_per_resolution = (len(train_loader) * hp.EPOCHS_PER_RESOLUTION[current_depth])
    fade_in_steps = int(total_steps_per_resolution * hp.FADE_IN_PERCENTAGE)

    # Implement a Cosine Annealing learning rate scheduler based around each resolution
    # REF: Inspiration to use a scheduler came from code generated by ChatGPT-4o using the following prompt.
    # REF: Prompt: What learning rate scheduler should I Choose for StyleGAN?
    gen_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(gen_opt, T_0=total_steps_per_resolution, T_mult=1)
    disc_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(disc_opt, T_0=total_steps_per_resolution, T_mult=1)

    # Loop over the total number of epochs per resolution
    for epoch in range(hp.EPOCHS_PER_RESOLUTION[current_depth]):

        # Start time of the epoch
        epoch_start_time = time.time()

        # Reset the data loader iterator
        data_iter = iter(train_loader)

        # Loop over each batch within the epoch 
        for i, (real_images, class_labels) in enumerate(data_iter):

            # Update alpha for fade-in phase
            if total_steps < fade_in_steps:
                alpha = total_steps / fade_in_steps
            else:
                alpha = 1.0 # Stabalisation phase

            # Move real images and labels from the ADNI dataset onto the GPU
            real_images = real_images.to(device)
            class_labels = class_labels.to(device)

            # Determine the batch size
            batch_size = real_images.size(0)

            # Create real, fake and random class labels
            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)
            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)
            rand_class_labels = torch.randint(0, hp.LABEL_DIMENSIONS, (batch_size,), device=device)

            # ---------------------------------------------------------------------------
            # (1) - Update the Discriminator by training with real images 
            # ---------------------------------------------------------------------------

            # Reset gradients of the discriminator
            disc.zero_grad()

            # Forward pass the real batch through the discriminator
            real_pred, class_real_pred, features_real = disc(real_images, labels=class_labels, depth=current_depth, alpha=alpha)

            # Calculate the real image discriminator losses
            real_loss_disc = adversial_criterion(real_pred.view(-1), real_labels)
            real_class_loss_disc = class_criterion(class_real_pred, class_labels)

            # Calculate average real prediction value of discriminator
            real_disc_avg = real_pred.mean().item()

            # Calculate the accuracy of the discriminator in classifying classes for real images
            predicted_classes = torch.argmax(class_real_pred, dim=1)
            correct_predictions = (predicted_classes == class_labels).float()
            real_class_disc_acc = correct_predictions.mean().item()

            # ---------------------------------------------------------------------------
            # (2) - Update the Discriminator by training with fake images (by generator)
            # ---------------------------------------------------------------------------

            # Generate a batch of latent vectors to input into the generator
            latent1 = torch.randn(batch_size, hp.LATENT_SIZE, device=device)

            # Create a second latent space batch randomly, for mixing regularisation
            if random.random() < hp.MIXING_PROB:
                latent2 = torch.randn(batch_size, hp.LATENT_SIZE, device=device)
            else:
                latent2 = None

            # Generate fake images using the generator and mixing regularisation
            fake_images = gen(latent1, latent2, mixing_ratio=random.uniform(0.5, 1.0), labels=rand_class_labels, depth=current_depth, alpha=alpha)

            # Apply the discriminator to classify fake images
            fake_pred, class_fake_pred, features_fake = disc(fake_images.detach(), labels=rand_class_labels, depth=current_depth, alpha=alpha)

            # Calculate the fake image discriminator losses
            fake_loss_disc = adversial_criterion(fake_pred.view(-1), fake_labels)
            fake_class_loss_disc = class_criterion(class_fake_pred, rand_class_labels)

            # Calculate average fake prediction value of discriminator
            fake_disc_avg = fake_pred.mean().item()

            # Calculate gradient penalty
            grad_penalty = compute_gradient_penalty(disc, real_images, fake_images, current_depth, device)

            # Calculate the total error of the discriminator
            tot_loss_disc = real_loss_disc + real_class_loss_disc + fake_loss_disc + fake_class_loss_disc + grad_penalty

            # Update the discriminator based on gradients and losses
            tot_loss_disc.backward()
            torch.nn.utils.clip_grad_norm_(disc.parameters(), max_norm=hp.DISC_GRAD_CLIP) # Gradient clipping used to decrease strength of discriminator
            grad_norm_disc = torch.nn.utils.clip_grad_norm_(disc.parameters(), max_norm=hp.DISC_GRAD_CLIP)
            disc_opt.step()

            # ---------------------------------------------------------------------------
            # (3) - Update the Generator with new fake images/labels
            # ---------------------------------------------------------------------------

            # Reset gradients of the generator
            gen.zero_grad()

            # Generate a batch of latent vectors to input into the generator
            latent1 = torch.randn(batch_size, hp.LATENT_SIZE, device=device)

            # Create a second latent space batch randomly, for mixing regularisation
            if random.random() < hp.MIXING_PROB:
                latent2 = torch.randn(batch_size, hp.LATENT_SIZE, device=device)
            else:
                latent2 = None

            # Generate fake images and labels
            rand_class_labels = torch.randint(0, hp.LABEL_DIMENSIONS, (batch_size,), device=device)
            fake_images = gen(latent1, latent2, mixing_ratio=random.uniform(0.5, 1.0), labels=rand_class_labels, depth=current_depth, alpha=alpha)

            # Forward pass fake images through discriminator (with updated discriminator)
            fake_pred, class_fake_pred, features_fake = disc(fake_images, labels=rand_class_labels, depth=current_depth, alpha=alpha)

            # Calculate the losses of the generator
            loss_gen = adversial_criterion(fake_pred.view(-1), real_labels)
            loss_class_gen = class_criterion(class_fake_pred, rand_class_labels)

            # Calculate the total loss of the generator
            tot_loss_gen = loss_gen + loss_class_gen + l2_regularisation(gen)

            # Calculate average output value of discriminator due to generator "real" images
            gen_avg = fake_pred.mean().item()

            # Update the generator based on gradients and losses
            tot_loss_gen.backward()
            torch.nn.utils.clip_grad_norm_(gen.parameters(), max_norm=hp.GEN_GRAD_CLIP) # Gradient clipping
            grad_norm_gen = torch.nn.utils.clip_grad_norm_(gen.parameters(), max_norm=hp.GEN_GRAD_CLIP)
            gen_opt.step()

            # ---------------------------------------------------------------------------
            # (4) - Logging and Statistics Output 
            # ---------------------------------------------------------------------------

            # Print statistics every 100 steps
            if total_steps % 100 == 0:
                print(f"[Resolution: {current_resolution}x{current_resolution}][Epoch: {epoch + 1}/{hp.EPOCHS_PER_RESOLUTION[current_depth]}][Step: {total_steps}/{total_steps_per_resolution}]\t"
                      f"Loss_D: {tot_loss_disc.item():.4f} | Loss_G: {tot_loss_gen.item():.4f} | Real Pred: {real_disc_avg:.4f} | Real Class Acc: {real_class_disc_acc:.4f} | Alpha: {alpha:.4f} "
                      f"| Disc Gradient: {grad_norm_disc:.4f} | Gen Gradient: {grad_norm_gen:.4f}")

            # Save Losses for plotting later
            G_losses.append(tot_loss_gen.item())
            D_losses.append(tot_loss_disc.item())

            # Regularly save an image out of the generator to see progress overtime 
            if (iters % 500 == 0) or (total_steps == total_steps_per_resolution- 1):
                with torch.no_grad():
                    fake = gen(fixed_noise, depth=current_depth, alpha=alpha).detach().cpu()
                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))

            iters += 1
            total_steps += 1

            # Step the schedulers at the end of each step/batch
            gen_scheduler.step()
            disc_scheduler.step()

        # Plot after each epoch to visualise training
        with torch.no_grad():
            fake = gen(fixed_noise, depth=current_depth, alpha=alpha).detach().cpu()
        plt.figure(figsize=(8,8))
        plt.axis("off")
        plt.title(f"Snippet of Image Generation at Resolution {current_resolution}x{current_resolution}")
        plt.imshow(np.transpose(vutils.make_grid(fake[:64], padding=2, normalize=True).cpu(),(1,2,0)))
        plt.savefig(os.path.join(hp.SAVED_OUTPUT_DIR, "during_training_images.png"), pad_inches=0)
        plt.close()

        # Epoch training time
        epoch_duration = ((time.time() - epoch_start_time) / 60) # In minutes
        print(f"Epoch [{epoch + 1}/{hp.EPOCHS_PER_RESOLUTION[current_depth]}] completed in {epoch_duration:.2f} minutes")

    # End of a resolution stage so save the images and models
    save_resolution(disc, gen, current_resolution, current_depth, device)


# Total training time 
total_training_time = ((time.time() - training_start_time) / 60) # In minutes
print(f"Total training time: {total_training_time:.2f} minutes")

# Save the models for later use in inference 
torch.save(gen.state_dict(), os.path.join(hp.SAVED_OUTPUT_DIR, "generator_model.pth"))
torch.save(disc.state_dict(), os.path.join(hp.SAVED_OUTPUT_DIR, "discriminator_model.pth"))

###################################### Training Loop End #################################

# REF: The following lines of code for plotting losses and image outputs was inspired by 
# REF: the following PyTorch tutorial: 
# REF: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html?highlight=dcgan.

# Output training loss plot
plt.figure(figsize=(10,5))
plt.title(f"Generator and Discriminator Loss During Training for {hp.NUM_OF_EPOCHS} Epochs")
plt.plot(G_losses,label="Generator")
plt.plot(D_losses,label="Discriminator")
plt.xlabel("Iterations")
plt.ylabel("Loss")
plt.legend()
plt.savefig(os.path.join(hp.SAVED_OUTPUT_DIR, "training_loss_plot.png"), pad_inches=0)
plt.close()

# Visualise the evolution of the generator 
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)
ani.save(os.path.join(hp.SAVED_OUTPUT_DIR, "image_generation_over_time.gif"), writer='pillow', fps=1) 

# Grab a batch of real images from the train_loader
real_batch = next(iter(train_loader))

# Plot the real images
plt.figure(figsize=(15,15))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))

# Plot the fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title(f"Generated Images - {hp.NUM_OF_EPOCHS} Epochs")
plt.imshow(np.transpose(img_list[-1],(1,2,0)))
plt.savefig(os.path.join(hp.SAVED_OUTPUT_DIR, "real_versus_fake_images.png"), bbox_inches='tight', pad_inches=0)
plt.close()
