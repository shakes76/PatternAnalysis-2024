# Alzheimer's Disease Classification Using Vision Transformers (Task 5)

Author: John Kong 46979597

## Problem Description

This project focuses on classifying Alzheimer's disease (AD) and normal cognition (NC) using brain MRI images from the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. We use a Vision Transformer (ViT) model to achieve this classification, leveraging its powerful capabilities in image recognition tasks. The goal is to distinguish between AD and NC with high accuracy, providing a deep learning-based approach to support medical diagnosis.

## The Model and How it works

The Vision Transformer (ViT) applies transformer architecture, which has been highly successful in natural language processing, to image data. In ViT, an image is divided into smaller, fixed-size patches which are then linearly embedded to create patch tokens. These tokens are treated as a sequence and processed through a series of transformer layers, utilizing multi-head self-attention mechanisms to learn global relationships between patches. The final output of the ViT is a class prediction, generated by passing the features from the last transformer block through a classification head, which outputs probabilities for each class. [1]

## Model Architecture

Vision Transformer Architecture:

![ViT model](Readme-imgs/VIT_architecture.png)

The Vision Transformer consists of several key components [2]:

1. **Patch Embedding**:

The input image is divided into fixed-size patches (e.g., 16x16 pixels). Each patch is flattened into a vector and linearly transformed into an embedding. These patch embeddings serve as the input tokens to the transformer.

2. **Positional Encoding**:

Since transformers do not inherently understand the spatial relationships between patches, positional encodings are added to the patch embeddings. These encodings provide information about the position of each patch within the image, enabling the model to consider spatial order.

3. **Transformer Encoder**:

The encoder consists of multiple layers of multi-head self-attention and feed-forward neural networks. The attention mechanism allows the model to focus on different patches when making predictions, while the feed-forward layers capture complex patterns and relationships between patches.

4. **Classification Head**:

A special classification token `CLS` is added to the sequence of patch embeddings. This token aggregates information from all patches through the transformer layers. The final state of this token is used as the image representation, which is passed through a fully connected layer to produce the output class (AD or NC).

## Implementation Details in `modules.py`

The code for the Vision Transformer is organized into four main classes [3]: 

1. **`PatchEmbedding`**:

This class splits the input image into patches and embeds each patch into a fixed-size vector using a linear layer. The patch embeddings are then combined with positional encodings to retain spatial information.

2. **`MultiHeadSelfAttention`**:

This class implements the multi-headed self-attention mechanism. The multi-head self-attention mechanism computes attention scores for each patch, determining the importance of different patches relative to each other. This mechanism is implemented using matrix multiplication and scaled dot-product attention. 

3. **`TransformerEncoderBlock`**: 

This class defines the structure of each transformer block, consisting of a multi-headed self-attention layer followed by a feed-forward neural network with skip connections and layer normalization. The feed-forward layer consists of two linear layers with a GELU (Gaussian Error Linear Unit) activation in between. The feed-forward network is applied independently to each token.

4. **`VisionTransformer`**:

This is the main class for the Vision Transformer model. It integrates all the components mentioned above and defines the forward pass for the entire architecture, from patch embedding to the classification head. 

## Data and Implementation Details in `dataset.py`

This file is responsible for data loading and preprocessing. It includes the following components [4]:

1. **Data Loading**:

The file defines functions to load the ADNI dataset and split it into training, validation, and test sets. The dataset is split with an 80-20 rule for training and validation, while a separate set is used for testing. The `get_data_loaders` function uses PyTorch’s `DataLoader` class to load and batch the data efficiently.

2. **Transforms**:

Several image transformations are applied to preprocess the data, including resizing, normalization, and augmentation such as random flips or rotations. Specifically, the dataset is normalized using `ImageNet`'s means and standard deviations and the images are also resized to `224x224` pixels, a typical input size for Vision Transformers [5]. These augmentations are designed to increase data diversity, helping the model generalize better to unseen images.

3. **Handling Class Imbalance**:

Handling class imbalance is a critical aspect when training machine learning models, especially in medical datasets like ADNI. In medical imaging datasets, it is common for one class (e.g., healthy controls, `NC`) to be overrepresented compared to another (e.g., diseased cases, `AD`). This creates a risk where the model might become biased, performing well on the majority class while failing to correctly identify the minority class. To address this, `dataset.py` computes `class_weights` to guide the model during training. It uses `class_weight.compute_class_weight` from `sklearn.utils` to calculate weights for each class based on their frequency, helping to balance the influence of each class in training.

4. **Handling Data Leakage**:

A patient-level split was employed using metadata to ensure all images from a single patient are grouped together in the same dataset split (train, validation). This approach was made possible by using the name of the image file, for example: `1003730_100.jpeg`, which indicates the patient IDs associated with each image. By grouping images based on patient IDs and splitting them accordingly, we ensured that no patient data overlapped between the different dataset partitions.

This method is crucial because it prevents data leakage, where the same patient's images could appear in both training and validation sets, leading to overfitting and inflated performance metrics. The patient-level split enhances the model's generalizability, as it simulates a realistic scenario in which the model must make predictions on unseen patients, making the results more reliable for clinical applications.

## Data Configuration and Data Example

The dataset is organized in the following folder structure and can be obtain from the Rangpur Path: `/home/groups/comp3710/ADNI`.

```
AD_NC
├── test
│   ├── AD
│   └── NC
└── train
    ├── AD
    └── NC
```

Below are some example of input images of the different classes:

AD:

![AD image 1](Readme-imgs/sample_train/AD/388206_85.jpeg)
![AD image 2](Readme-imgs/sample_train/AD/388206_86.jpeg)

NC:

![NC image 1](Readme-imgs/sample_train/NC/1182968_105.jpeg)
![NC image 2](Readme-imgs/sample_train/NC/1182968_106.jpeg)

## Dependencies

To run this project, you will need the following dependencies:

```
Python 3.8+
PyTorch 1.12+
torchvision 0.13+
scikit-learn 1.0+
matplotlib 3.5+
numpy 1.21+
```

## Usage

To train the model, run:

```python train.py```

To evaluate the model, run:

```python predict.py```

Look at `.sh` file to run it on the HPC 

## Training Process

### Initial Training Process and Parameters 

The initial training configuration for the Vision Transformer included a learning rate of `3e-4`, a weight decay of `1e-5`, and a batch size of `32`. The model used a dropout rate of `0.1` and a patience value of `20` epochs for early stopping to mitigate overfitting. The optimizer chosen was `Adam`, suitable for training Vision Transformers due to its adaptive learning rate mechanism, and the loss function used was `CrossEntropyLoss`, a standard choice for multi-class classification tasks like this.

### Hyperparameter Tuning Process

In this project, several key hyperparameters were systematically tuned to optimize model performance and address issues such as overfitting. The selection of these hyperparameters was guided by their impact on the model's learning dynamics and generalization capabilities (test accuracy).

Here’s a breakdown of the hyperparameters chosen for tuning and the rationale behind each:

1. **Number of Epochs**:

The number of training epochs was tested as a straightforward way to determine if extending training time alone could improve test accuracy. Additionally, I wanted to use the epochs to  experiment with the time constraints and computational limits on Rangpur. By adjusting epochs from `30`, `50`, `80`, and up to `200`, the goal was to observe if a prolonged training period would allow the model to converge better on the validation and testing sets.

2. **Learning Rate**:

The learning rate dictates how quickly or slowly the model updates its weights during training. Tuning this parameter is crucial because a learning rate that is too high might cause the model to converge too quickly, potentially missing the optimal point, while a rate that is too low may result in slow convergence or getting stuck in a local minimum. A range of values around the initial learning rate of `3e-4` (e.g., `1e-4` to `5e-4`) was tested to identify the optimal balance.

3. **Batch Size**:

The batch size affects both the model's learning process and computational efficiency. A smaller batch size, while more computationally demanding, can lead to more frequent updates and better generalization, while a larger batch size offers stability in the gradient updates. By tuning this parameter, the aim was to observe how varying sizes (e.g., `16`, `32`, `64`) influence the accuracy and speed of convergence.

4. **Dropout Rate**:

Dropout is a regularization technique that helps prevent overfitting by randomly setting a fraction of input units to zero during training. The initial dropout value was set to `0.1`, and this was varied (e.g., `0.1`, `0.3`, `0.5`) to assess its impact on the model’s ability to generalize better to unseen data.

5. **Weight Decay**:

Weight decay adds a penalty to the loss function based on the magnitude of the model weights, encouraging the network to learn simpler, more generalizable patterns. The initial value was set to `1e-5`, and various values (`1e-4`, `5e-5`, `1e-6`) were tested to reduce overfitting and improve test performance by regulating model complexity.

**Addtional Notes**:

I also experimented with the SGD (Stochastic Gradient Descent) optimizer as a brief initial experiment. However, the results weren't as promising, leading to lower validation accuracy and slower convergence. Consequently, I reverted to using Adam, which offered more stability and faster convergence.

## Training Results and Evaluation

### Hyperparameter Tuning Results

1. **Epoch Tuning**

_Parameters kept constant: learning rate = 3e-4, weight decay = 1e-5, batch size = 32, dropout = 0.1._

| Epochs | Best Validation Accuracy (%) | Test Accuracy (%) | Early Stopping |
|--------|------------------------------|-------------------|----------------|
| 30     | 68.1                        | 65.0              | No              |
| 50     | 51.2                        | 50.4              | Yes             |
| 80     | 72.0                        | **67.2**          | No              |
| 200    | 82.0                        | 65.3              | No              | 

2. **Learning Rate Tuning**

_Parameters kept constant: epochs = 80, weight decay = 1e-5, batch size = 32, dropout = 0.1._

| Learning Rate | Best Validation Accuracy (%) | Test Accuracy (%) | Early Stopping |
|---------------|------------------------------|-------------------|----------------|
| 1e-4          | 77.4                        | 64.9              | No            |
| 3e-4          | 72.0                        | **67.2**          | No             |
| 5e-4          | 72.3                        | 66.1              | No            |

3. **Dropout Tuning**

_Parameters kept constant: epochs = 80, learning rate = 3e-4, weight decay = 1e-5, batch size = 32._

| Dropout | Best Validation Accuracy (%) | Test Accuracy (%) | Early Stopping |
|---------|------------------------------|-------------------|----------------|
| 0.1     | 72.0                        | **67.2**         | No             |
| 0.3     | 64.5                        | 63.6              | Yes            |
| 0.5     | 60.8                        | 58.9              | Yes            |

4. **Batch Size Tuning**

_Parameters kept constant: epochs = 80, learning rate = 3e-4, weight decay = 1e-5, dropout = 0.1._

| Batch Size | Best Validation Accuracy (%) | Test Accuracy (%) | Early Stopping |
|------------|------------------------------|-------------------|----------------|
| 8          | 73.6                        | 66.3              | No             |
| 16         | 70.1                        | **67.0**          | No             |
| 32         | 72.2                        | **67.2**          | No             |
| 64         | 72.6                        | 65.6              | No            |

5. **Weight Decay Tuning**

_Parameters kept constant: epochs = 80, learning rate = 3e-4, batch size = 32, dropout = 0.1._

| Weight Decay | Best Validation Accuracy (%) | Test Accuracy (%) | Early Stopping |
|--------------|------------------------------|-------------------|----------------|
| 1e-6         | 51.2                        | 50.9              | Yes             |
| 1e-5         | 72.2                        |**67.2**           | No             |
| 1e-4         | 62.4                        | 59.3              | No            |

### Some Worst Plots Outputs

In this section, we first present the worst-case plots to illustrate the impact of inappropriate hyperparameter settings and the model's response. These plots reveal significant discrepancies between training and validation curves, showing evidence of overfitting, instability, and poor generalization performance. 

Some example of **worst plots** from inapporiate hyperparameters:

![worst plot 1](Results/res_17_1e-6Decay_bad/accuracy_curve.png)
![worst plot 2](Results/res_17_1e-6Decay_bad/loss_curve.png)

![worst plot 1](Results/res_16_1-e4Decay_bad/accuracy_curve.png)
![worst plot 2](Results/res_16_1-e4Decay_bad/loss_curve.png)

Following this, we present the best-case plots, which demonstrate the improvements and stability achieved after further fine-tuning. 

### Best Hyperparameters and Plots

After hyperparameter fine-tuning, the best parameters were determined as follows:

**epochs = 80, learning rate = 3e-4, batch size = 32, dropout = 0.1, weight decay = 1e-5**

The results of training using these hyperparameters are illustrated in the following plots. 

**Best Accuracy Curve**:

![best plot 1](Results/res_7_80epoch/accuracy_curve.png)

The training and validation accuracies are relatively close together, indicating that the model is learning effectively and generalizing well within these parameters. While the training accuracy shows less fluctuation, the validation accuracy exhibits wider variations, suggesting that the model is somewhat sensitive to different validation batches.  At around the 11th epoch, both the training and validation accuracies sharply increase, indicating a significant learning point where the model adjusts its parameters effectively. It shows that the model found a good set of features early on but needed further epochs to refine the accuracy.

**Best Loss Curve**:

![best plot 1](Results/res_7_80epoch/loss_curve.png)

Both the training and validation losses generally follow a downward trend, indicating that the model is learning to minimize errors. At around the 20th epoch, the curves align closely, suggesting that the model's performance is balanced between training and validation at this stage. Beyond this point, the validation loss starts fluctuating significantly, with no clear trend. This variability implies that while the model performs well on the training set, it struggles with generalizing to unseen data. The wild fluctuations and lack of trend in the validation loss curve highlight potential overfitting, as the model may be adapting too specifically to the training data.

Overall, the **best test accuracy of 67.2%** is slightly lower than the best validation accuracy of 72%, meaning that there is still overfitting.

### Evaluation in `predict.py`

The `predict.py` script is designed to demonstrate how the trained model can be used to make predictions on new data. It showcases the inference process and provides example usage by loading the best model, processing input images, and predicting class labels. 

To evaluate the model's performance visually, the script displays a **confusion matrix** based on the model's predictions against ground truth labels.

Here are some **inference results** from the best model:

<img src="Results/res_7_80epoch/confusion_matrix.png" alt="inference plot 1" width="400" height="400"/>
<img src="Results/res_7_80epoch/prediction_visualization.png" alt="inference plot 2" width="500" height="400"/>

## References

- [1]: Vision transformer. (2023, August 6). Wikipedia. https://en.wikipedia.org/wiki/Vision_transformer
- [2]: Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., & Houlsby, N. (2021). AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE. https://arxiv.org/pdf/2010.11929
- [3]: lucidrains. (2024). GitHub - lucidrains/vit-pytorch: Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch. GitHub. https://github.com/lucidrains/vit-pytorch?tab=readme-ov-file
- [4]: Datasets & DataLoaders — PyTorch Tutorials 1.11.0+cu102 documentation. (2024). Pytorch.org. https://pytorch.org/tutorials/beginner/basics/data_tutorial.html
- [5]: Vision Transformer (ViT). (2019). Huggingface.co. https://huggingface.co/transformers/v4.9.1/model_doc/vit.html

